{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Findings.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Existing feasible solutions for ML with imbalanced dataset**\n",
        "\n",
        "\n",
        "1.   Weighting the classes based on the sample size per class in training set [3, 8]\n",
        "2.   Resampling the training set based on the class ratio (keep it minimal in general cases), but it uses bayesian ML model protentially due to the sample size is reduced. [1, 8]\n",
        "3.   Reduce the redentant/confusing group/class by clustering method on the features (e.g. KMean) [1]\n",
        "4.   Breaking down a single machine learning model into servals models to fitting different classes based on the class ratio, then ensemble all the models at last [1, & I do have a unpublish paper for this method]\n",
        "5.   Select the suitable metrics [1]\n",
        "6.   Using Variational Autoencoder(VAE) to generating the samples for the class with less sample [9]\n",
        "7.   Using Baysian Network with Variational Inference (VI) [8, 10]\n"
      ],
      "metadata": {
        "id": "Iy5KGDHz1z3M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the work, it focus on the solution 7. using baysian learning to solve the imbalanced data problem. Lee [8] proposed method leaveraging the bayesian inference on the solution 1) and the weights effects the learnable parameters of the neural network directly.\n",
        "\n",
        "The Idea about considering bayesian technique to solving the imbalanced training data is because bayesian inference/bayesian network is not a determistic algorithm. On the other hand, the determistic machine learning model would mainly depend on the data size, therefore robustness about determistic machine learning model is proportional to the variation and the size of data. To that reason, solution 2.) will discount the accuracy or the robustness of the determistic model, but bayesian method will not suffer from this problem. \n",
        "\n",
        "In the paper, $w^{t}$ is the learnable parameter for class-imbalance model, and it is denoated by variational inference. \n",
        "\n",
        "Recall the bayesian inference equation: \n",
        "\n",
        "$P(w^{t}|X)=P(X|w^{t}) · P(w^{t})) · P(X)^{-1} \\tag{1}$\n",
        "\n",
        "$P(w^{t}|X) \\propto P(X|w^{t}) · P(w^{t})) \\tag{2}$\n",
        "\n",
        "In general, $P(w^{t})$ is difficult to define a analytical solution, therefore the researcher/data scientist would using the approximation techniques or sampling techniques to computing $P(w^{t})$. Due the regulation of $P(w^t)$, the approximation/sampling techniques is not computing the $w^t$ directly, it tricks $w^t(σ,μ)$ and appliy the techniques on $σ$ and $\\mu$ instead."
      ],
      "metadata": {
        "id": "YWeywkLd-ED9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code for Lee [8] method can be found in [7] and the datasets for their experiment can be found in [4, 5, 6]\n",
        "\n",
        "In conclude, bayesian method owns the sideback which is difficult to implement and design compared with the determistic model. Therefore selection on the solutions in the first section depends on the project timeline, resources and the business scope/objective."
      ],
      "metadata": {
        "id": "7sDnPcjlV3Bd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QDP3ns2j1shn"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Reference***\n",
        "\n",
        "1.   https://www.kdnuggets.com/2017/06/7-techniques-handle-imbalanced-data.html\n",
        "2.   https://machinelearningmastery.com/cross-validation-for-imbalanced-classification/#:~:text=493%2C%201%3D7-,Fix%20Cross%2DValidation%20for%20Imbalanced%20Classification,class%20distribution%20in%20each%20subset.\n",
        "3.   https://www.analyticsvidhya.com/blog/2020/10/improve-class-imbalance-class-weights/\n",
        "4.   https://github.com/zalandoresearch/fashion-mnist\n",
        "5.   http://ufldl.stanford.edu/housenumbers\n",
        "6.   https://github.com/bertinetto/r2d2\n",
        "7.   https://github.com/haebeom-lee/l2b\n",
        "8.   Lee, Hae Beom, et al. \"Learning to balance: Bayesian meta-learning for imbalanced and out-of-distribution tasks.\" arXiv preprint arXiv:1905.12917 (2019).\n",
        "9.   Fajardo, Val Andrei, et al. \"Vos: a method for variational oversampling of imbalanced data.\" arXiv preprint arXiv:1809.02596 (2018).\n",
        "10.  Brodersen, Kay H., et al. \"Variational Bayesian mixed-effects inference for classification studies.\" Neuroimage 76 (2013): 345-361.\n",
        "\n"
      ],
      "metadata": {
        "id": "oyqhfx-m3Qc5"
      }
    }
  ]
}