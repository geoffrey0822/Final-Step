{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "q2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UHSvmoP5h2OZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e808e67a-42b9-4f88-ea52-04532f685ba6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/mil_ird_challenge.zip\n",
            "replace mil_ird_challenge/.DS_Store? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "!unzip /content/drive/MyDrive/mil_ird_challenge.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "train_root_path = '/content/mil_ird_challenge/train/'\n",
        "test_root_path = '/content/mil_ird_challenge/test/'\n",
        "\n",
        "train_set = []\n",
        "test_set = []\n",
        "for cls in os.listdir(train_root_path):\n",
        "  cls_path = os.path.join(train_root_path,cls)\n",
        "  if os.path.isdir(cls_path):\n",
        "    for fname in os.listdir(cls_path):\n",
        "      f_low = fname.lower()\n",
        "      if f_low.endswith('.png') or f_low.endswith('.jpg'):\n",
        "        f_path = os.path.join(cls_path, fname)\n",
        "        train_set.append((cls, f_path))\n",
        "\n",
        "for cls in os.listdir(test_root_path):\n",
        "  cls_path = os.path.join(test_root_path,cls)\n",
        "  if os.path.isdir(cls_path):\n",
        "    for fname in os.listdir(cls_path):\n",
        "      f_low = fname.lower()\n",
        "      if f_low.endswith('.png') or f_low.endswith('.jpg'):\n",
        "        f_path = os.path.join(cls_path, fname)\n",
        "        test_set.append((cls, f_path))\n",
        "\n",
        "train_df = pd.DataFrame(data=train_set, columns=['class', 'path'])\n",
        "test_df = pd.DataFrame(data=test_set, columns=['class', 'path'])\n",
        "print(train_df.shape)\n",
        "print(test_df.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KEAtyn5Liliq",
        "outputId": "67efcb1b-fa32-4e37-c653-a3acd808a87d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(13953, 2)\n",
            "(3000, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.groupby('class').count().describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "cLRhEGyloAmy",
        "outputId": "39fb6847-df75-40ac-cb22-7d5dce434d07"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-d36232fd-69d1-4d2c-9b27-129a3761c9e5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>6.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>2325.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>117.716184</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>2175.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2257.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>2309.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>2393.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>2498.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d36232fd-69d1-4d2c-9b27-129a3761c9e5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d36232fd-69d1-4d2c-9b27-129a3761c9e5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d36232fd-69d1-4d2c-9b27-129a3761c9e5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "              path\n",
              "count     6.000000\n",
              "mean   2325.500000\n",
              "std     117.716184\n",
              "min    2175.000000\n",
              "25%    2257.000000\n",
              "50%    2309.500000\n",
              "75%    2393.500000\n",
              "max    2498.000000"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!git clone https://github.com/facebookresearch/FixRes.git"
      ],
      "metadata": {
        "id": "NI5qc6p2qaMC"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "GFcBrA5FtH7W"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import datasets, models, transforms\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import time, copy\n",
        "#from FixRes.transforms_v2 import get_transforms\n",
        "\n",
        "def set_parameter_requires_grad(model, feature_extracting):\n",
        "  if feature_extracting:\n",
        "    for param in model.parameters():\n",
        "      param.requires_grad = False\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "torch.cuda.is_available()\n",
        "\n",
        "#transform = get_transforms(input_size=480, test_size=480)\n",
        "#act_train_set = datasets.ImageFolder(train_root_path, transform=transform['val_train'])\n",
        "#act_test_set = datasets.ImageFolder(test_root_path, transform=transform['val_test'])\n",
        "\n",
        "batch_size = 32\n",
        "n_epochs = 30\n",
        "n_classes = train_df['class'].nunique()\n",
        "\n",
        "model_ft = models.resnet50(pretrained=True)\n",
        "set_parameter_requires_grad(model_ft, feature_extracting=True)\n",
        "num_ftrs = model_ft.fc.in_features\n",
        "model_ft.fc = nn.Linear(num_ftrs, n_classes)\n",
        "input_size = 224\n"
      ],
      "metadata": {
        "id": "o2OtmUTPqFBD"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, is_inception=False):\n",
        "    since = time.time()\n",
        "\n",
        "    val_acc_history = []\n",
        "    \n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    # Get model outputs and calculate loss\n",
        "                    # Special case for inception because in training it has an auxiliary output. In train\n",
        "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
        "                    #   but in testing we only consider the final output.\n",
        "                    if is_inception and phase == 'train':\n",
        "                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
        "                        outputs, aux_outputs = model(inputs)\n",
        "                        loss1 = criterion(outputs, labels)\n",
        "                        loss2 = criterion(aux_outputs, labels)\n",
        "                        loss = loss1 + 0.4*loss2\n",
        "                    else:\n",
        "                        outputs = model(inputs)\n",
        "                        loss = criterion(outputs, labels)\n",
        "\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
        "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            if phase == 'val':\n",
        "                val_acc_history.append(epoch_acc)\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, val_acc_history"
      ],
      "metadata": {
        "id": "FQZYZ-WwC7rB"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(input_size),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(input_size),\n",
        "        transforms.CenterCrop(input_size),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "act_train_set = datasets.ImageFolder(train_root_path, transform=data_transforms['train'])\n",
        "act_test_set = datasets.ImageFolder(test_root_path, transform=data_transforms['val'])\n",
        "image_datasets = {'train': act_train_set, 'val': act_test_set}\n",
        "\n",
        "dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=4) for x in ['train', 'val']}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dMStbwSF_43W",
        "outputId": "be22e053-4f69-496d-b9e4-d22c3426d7a4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initial Optimizer and finetuning"
      ],
      "metadata": {
        "id": "qzwMCkEsAeWX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_ft = model_ft.to(device)\n",
        "\n",
        "params_to_update = model_ft.parameters()\n",
        "params_to_update = []\n",
        "for name,param in model_ft.named_parameters():\n",
        "  if param.requires_grad == True:\n",
        "    params_to_update.append(param)\n",
        "    print(\"\\t\",name)\n",
        "\n",
        "optimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.99)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Train and evaluate\n",
        "model_ft, hist = train_model(model_ft, dataloaders_dict, criterion, optimizer_ft, num_epochs=n_epochs, is_inception=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0D1ldEtUAdT2",
        "outputId": "731855bc-a1ba-424f-b10a-9ea7d2d02bcd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t fc.weight\n",
            "\t fc.bias\n",
            "Epoch 0/29\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 0.6941 Acc: 0.7881\n",
            "val Loss: 0.3389 Acc: 0.8970\n",
            "\n",
            "Epoch 1/29\n",
            "----------\n",
            "train Loss: 0.5971 Acc: 0.8203\n",
            "val Loss: 0.3954 Acc: 0.8767\n",
            "\n",
            "Epoch 2/29\n",
            "----------\n",
            "train Loss: 0.5771 Acc: 0.8266\n",
            "val Loss: 0.3427 Acc: 0.8923\n",
            "\n",
            "Epoch 3/29\n",
            "----------\n",
            "train Loss: 0.5870 Acc: 0.8230\n",
            "val Loss: 0.5427 Acc: 0.8507\n",
            "\n",
            "Epoch 4/29\n",
            "----------\n",
            "train Loss: 0.5947 Acc: 0.8276\n",
            "val Loss: 0.3146 Acc: 0.9067\n",
            "\n",
            "Epoch 5/29\n",
            "----------\n",
            "train Loss: 0.4908 Acc: 0.8377\n",
            "val Loss: 0.3949 Acc: 0.8837\n",
            "\n",
            "Epoch 6/29\n",
            "----------\n",
            "train Loss: 0.4909 Acc: 0.8398\n",
            "val Loss: 0.3029 Acc: 0.9007\n",
            "\n",
            "Epoch 7/29\n",
            "----------\n",
            "train Loss: 0.5564 Acc: 0.8312\n",
            "val Loss: 0.3368 Acc: 0.8963\n",
            "\n",
            "Epoch 8/29\n",
            "----------\n",
            "train Loss: 0.4927 Acc: 0.8383\n",
            "val Loss: 0.3859 Acc: 0.8867\n",
            "\n",
            "Epoch 9/29\n",
            "----------\n",
            "train Loss: 0.4942 Acc: 0.8408\n",
            "val Loss: 0.2611 Acc: 0.9150\n",
            "\n",
            "Epoch 10/29\n",
            "----------\n",
            "train Loss: 0.5185 Acc: 0.8433\n",
            "val Loss: 0.2891 Acc: 0.9073\n",
            "\n",
            "Epoch 11/29\n",
            "----------\n",
            "train Loss: 0.4761 Acc: 0.8453\n",
            "val Loss: 0.3438 Acc: 0.8813\n",
            "\n",
            "Epoch 12/29\n",
            "----------\n",
            "train Loss: 0.5365 Acc: 0.8316\n",
            "val Loss: 0.3787 Acc: 0.8767\n",
            "\n",
            "Epoch 13/29\n",
            "----------\n",
            "train Loss: 0.5691 Acc: 0.8336\n",
            "val Loss: 0.3639 Acc: 0.8923\n",
            "\n",
            "Epoch 14/29\n",
            "----------\n",
            "train Loss: 0.4742 Acc: 0.8456\n",
            "val Loss: 0.3958 Acc: 0.8720\n",
            "\n",
            "Epoch 15/29\n",
            "----------\n",
            "train Loss: 0.4489 Acc: 0.8527\n",
            "val Loss: 0.3267 Acc: 0.8890\n",
            "\n",
            "Epoch 16/29\n",
            "----------\n",
            "train Loss: 0.4925 Acc: 0.8384\n",
            "val Loss: 0.3346 Acc: 0.8957\n",
            "\n",
            "Epoch 17/29\n",
            "----------\n",
            "train Loss: 0.4502 Acc: 0.8469\n",
            "val Loss: 0.4987 Acc: 0.8607\n",
            "\n",
            "Epoch 18/29\n",
            "----------\n",
            "train Loss: 0.5119 Acc: 0.8418\n",
            "val Loss: 0.4286 Acc: 0.8750\n",
            "\n",
            "Epoch 19/29\n",
            "----------\n",
            "train Loss: 0.5146 Acc: 0.8465\n",
            "val Loss: 0.3774 Acc: 0.8903\n",
            "\n",
            "Epoch 20/29\n",
            "----------\n",
            "train Loss: 0.5016 Acc: 0.8444\n",
            "val Loss: 0.2834 Acc: 0.9113\n",
            "\n",
            "Epoch 21/29\n",
            "----------\n",
            "train Loss: 0.5157 Acc: 0.8472\n",
            "val Loss: 0.3680 Acc: 0.8913\n",
            "\n",
            "Epoch 22/29\n",
            "----------\n",
            "train Loss: 0.4328 Acc: 0.8564\n",
            "val Loss: 0.3068 Acc: 0.8987\n",
            "\n",
            "Epoch 23/29\n",
            "----------\n",
            "train Loss: 0.4541 Acc: 0.8499\n",
            "val Loss: 0.3517 Acc: 0.8960\n",
            "\n",
            "Epoch 24/29\n",
            "----------\n",
            "train Loss: 0.5183 Acc: 0.8446\n",
            "val Loss: 0.2704 Acc: 0.9147\n",
            "\n",
            "Epoch 25/29\n",
            "----------\n",
            "train Loss: 0.4119 Acc: 0.8584\n",
            "val Loss: 0.3098 Acc: 0.9000\n",
            "\n",
            "Epoch 26/29\n",
            "----------\n",
            "train Loss: 0.4547 Acc: 0.8543\n",
            "val Loss: 0.3488 Acc: 0.8920\n",
            "\n",
            "Epoch 27/29\n",
            "----------\n",
            "train Loss: 0.4236 Acc: 0.8582\n",
            "val Loss: 0.2934 Acc: 0.9003\n",
            "\n",
            "Epoch 28/29\n",
            "----------\n",
            "train Loss: 0.4064 Acc: 0.8591\n",
            "val Loss: 0.2829 Acc: 0.9027\n",
            "\n",
            "Epoch 29/29\n",
            "----------\n",
            "train Loss: 0.5224 Acc: 0.8408\n",
            "val Loss: 0.4772 Acc: 0.8683\n",
            "\n",
            "Training complete in 21m 37s\n",
            "Best val Acc: 0.915000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model_ft.state_dict(), '/content/drive/MyDrive/trained/model.pt')\n",
        "torch.save(model_ft.state_dict(), 'model.pt')"
      ],
      "metadata": {
        "id": "Dk_UsP_ZJWJV"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "preprocess = transforms.Compose([\n",
        "        transforms.Resize(input_size),\n",
        "        transforms.CenterCrop(input_size),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "pred_root_path = '/content/mil_ird_challenge/pred/'\n",
        "#pred_set = datasets.ImageFolder(pred_root_path, transform=data_transforms['val'])\n",
        "pred_labels = []\n",
        "model_ft.eval()\n",
        "for fname in os.listdir(pred_root_path):\n",
        "  fpath = os.path.join(pred_root_path, fname)\n",
        "  img = Image.open(fpath)\n",
        "  img_p = preprocess(img)\n",
        "  img_p_tensor = torch.unsqueeze(img_p, 0).cuda()\n",
        "  #display(img_p)\n",
        "  pred_lbl = torch.argmax(model_ft(img_p_tensor)).item()\n",
        "  pred_labels.append([fname, pred_lbl])\n",
        "  #print(pred_lbl)\n",
        "  #break\n",
        "#print(pred_labels)\n",
        "res_df = pd.DataFrame(data = pred_labels, columns=['filename', 'class_prediction'])\n",
        "display(res_df)\n",
        "res_df.to_csv('prediction_result.csv')\n",
        "res_df.to_csv('/content/drive/MyDrive/trained/prediction_result.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "FFeOgxPGKDJ_",
        "outputId": "31a4eb5e-7934-4ffc-e633-2b4ed1a3ddf4"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-db6f11b9-c195-408e-8702-e3b94559befb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>class_prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17410.jpg</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1763.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>17315.jpg</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>17600.jpg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1730.jpg</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>174.jpg</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>17347.jpg</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>17590.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79</th>\n",
              "      <td>17673.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80</th>\n",
              "      <td>1731.jpg</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>81 rows Ã— 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-db6f11b9-c195-408e-8702-e3b94559befb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-db6f11b9-c195-408e-8702-e3b94559befb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-db6f11b9-c195-408e-8702-e3b94559befb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     filename  class_prediction\n",
              "0   17410.jpg                 4\n",
              "1    1763.jpg                 0\n",
              "2   17315.jpg                 5\n",
              "3   17600.jpg                 1\n",
              "4    1730.jpg                 5\n",
              "..        ...               ...\n",
              "76    174.jpg                 4\n",
              "77  17347.jpg                 5\n",
              "78  17590.jpg                 0\n",
              "79  17673.jpg                 0\n",
              "80   1731.jpg                 5\n",
              "\n",
              "[81 rows x 2 columns]"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}